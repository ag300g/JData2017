library(xgboost)
30539 * 1.15
21649 * 1.15
3000 * (21445 / 1997)
2500*((20768 + 2633)/(1847 + 208))
1000 * 1.5^9
setwd("E:/git-src/JData2017/rcode")
library(data.table)
library(dplyr)
library(xgboost)
offline_train <- fread('../data/offline_train_20170510090241.txt')
offline_prediction_x <- fread('../data/offline_prediction_20170510090531.txt')
offline_verify <- fread('../data/offline_verify_20170510090601.txt')
head(offline_train)
library(data.table)
library(dplyr)
library(xgboost)
offline_train <- fread('../data/offline_train_20170510090241.txt')
offline_prediction_x <- fread('../data/offline_prediction_20170510090531.txt')
offline_verify <- fread('../data/offline_verify_20170510090601.txt')
label <- offline_train$label
user_id <- offline_train$user_id
offline_train$user_id <- NULL
offline_train$sku_id <- NULL
offline_train$label <- NULL
offline_train$stat_day_cnt <- NULL
# 构建均衡训练集
train_sample_true <- which(label == 1)
train_sample_false <- which(label == 0)
balanced_sample_size <- ceiling(length(train_sample_true) * 1.3)
true_index <- train_sample_true
false_index <- train_sample_false[sample(1:length(train_sample_false), balanced_sample_size)]
balanced_index <- c(true_index, false_index)
dtrain_balanced <- xgb.DMatrix(data = as.matrix(1.0*offline_train[balanced_index, ]),
label=label[balanced_index])
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=10, eta=0.01, subsample=0.9)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=200, nfold=5)
train.xgboost.balanced <- xgb.train(data=dtrain_balanced, params=params, nrounds=1000)
dtrain <- xgb.DMatrix(data = as.matrix(1.0*offline_train), label=label)
model <- train.xgboost.balanced
pred <- predict(model, dtrain)
tmp <- data.frame(label, pred)
tmp <- tmp %>% arrange(desc(pred))
precision <- sum(tmp$label[1:12000]) / 12000
recall <- sum(tmp$label[1:12000]) / sum(tmp$label)
f11 <- 6*recall*precision / (5*recall + precision)
verify_user_id <- offline_prediction_x$user_id
offline_prediction_x$user_id <- NULL
offline_prediction_x$stat_day_cnt <- NULL
dtest <- xgb.DMatrix(data=as.matrix(1.0*offline_prediction_x))
pred <- predict(model, dtest)
result <- data.frame(user_id=verify_user_id, prob=pred)
result <- left_join(result, offline_verify, by=c('user_id')) %>% arrange(desc(prob))
result$label <- as.numeric(!is.na(result$sku_id))
precision <- sum(result$label[1:12000]) / 12000
recall <- sum(result$label[1:12000]) / sum(result$label)
f11 <- 6*recall*precision / (5*recall + precision)
as.Date('2016-04-08') - as.Date('2016-03-01') + 1
as.Date('2016-04-15') - as.Date('2016-03-01') + 1
3976+1204
rm(list = ls())
gc()
load('E:/JData2017/action_all.RData')
gc()
head(action_all)
test_period <- action_all %>% filter(time >= '2016-04-09' & time < '2016-04-14')
head(test.data.table())
head(test_period)
test_period_cate6 <- test_period %>% filter(cate == 6)
rm(list = c('err'))
gc()
head(test_period_cate6)
test_period_cate6_type4 <- test_period_cate6 %>% filter(type == 4)
head(test_period_cate6_type4)
test_period_cate6_type4 <- test_period_cate6_type4 %>% arrange(user_id, time)
test_period_cate6_type4
test_period_cate6_type4
test_period_cate6_type4 %>% group_by(sku_id) %>% summarise(cnt=n())
test_period_cate6_type4 %>% group_by(sku_id) %>% summarise(cnt=n())
library(dplyr)
test_period_cate6_type4 %>% group_by(sku_id) %>% summarise(cnt=n())
test_period_cate6_type4 %>% group_by(sku_id) %>% summarise(n())
test_period_cate6_type4 %>% group_by(sku_id) %>% summarise_(cnt=n())
library(data.table)
head(test_period_cate6_type4)
test_period_cate6_type4 %>% group_by(sku_id) %>% summarise(cnt=n())
?n
class(test_period_cate6_type4)
conflicts()
test_period_cate6_type4 %>% group_by(sku_id) %>% dplyr::summarise(cnt=n())
test_period_cate6_type4 %>% group_by(sku_id) %>% dplyr::summarise(cnt=n()) %>% arrange(desc(cnt))
cc <- test_period_cate6_type4 %>% group_by(sku_id) %>% dplyr::summarise(cnt=n()) %>% arrange(desc(cnt))
summary(cc$cnt)
hist(cc$cnt)
View(cc)
head(test_period_cate6_type4)
tmp <- action_all %>% filter(user_id == 118)
tmp <- action_all %>% filter(user_id == 118) %>% arrange(time)
View(tmp)
View(test_period_cate6_type4)
tmp <- action_all %>% filter(user_id == 106) %>% arrange(time)
View(tmp)
getwd()
rm(list = ls())
gc()
library(data.table)
library(dplyr)
library(xgboost)
online_train <- fread('../data/online_train_20170510114201.txt')
online_prediction_x <- fread('../data/online_prediction_20170510113551.txt')
label <- online_train$label
user_id <- online_train$user_id
online_train$user_id <- NULL
online_train$sku_id <- NULL
online_train$label <- NULL
online_train$stat_day_cnt <- NULL
# 构建均衡训练集
train_sample_true <- which(label == 1)
train_sample_false <- which(label == 0)
balanced_sample_size <- ceiling(length(train_sample_true) * 1.3)
true_index <- train_sample_true
false_index <- train_sample_false[sample(1:length(train_sample_false), balanced_sample_size)]
balanced_index <- c(true_index, false_index)
dtrain_balanced <- xgb.DMatrix(data = as.matrix(1.0*online_train[balanced_index, ]),
label=label[balanced_index])
params <- list(objective="binary:logistic", nthread=5, max_depth=10, eta=0.01, subsample=0.9)
train.xgboost.balanced <- xgb.train(data=dtrain_balanced, params=params, nrounds=1000)
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_train), label=label)
model <- train.xgboost.balanced
pred <- predict(model, dtrain)
tmp <- data.frame(label, pred)
tmp <- tmp %>% arrange(desc(pred))
precision <- sum(tmp$label[1:12000]) / 12000
recall <- sum(tmp$label[1:12000]) / sum(tmp$label)
f11 <- 6*recall*precision / (5*recall + precision)
head(online_prediction_x)
# 提交预测
user_id <- online_prediction_x$user_id
online_prediction_x$user_id <- NULL
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_prediction_x), label=label)
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_prediction_x))
pred <- predict(model, dtrain)
length(pred)
head(result)
source('E:/git-src/JData2017/rcode/online_pipeline.R', encoding = 'UTF-8', echo=TRUE)
head(result)
load('E:/JData2017/action_all.RData')
?fread
rm(list = ls())
gc()
library(data.table)
library(dplyr)
library(xgboost)
online_train <- fread('../data/online_train_20170510114201.txt', na.strings = c('NULL'))
online_prediction_x <- fread('../data/online_prediction_20170510113551.txt')
label <- online_train$label
user_id <- online_train$user_id
online_train$user_id <- NULL
online_train$sku_id <- NULL
online_train$label <- NULL
online_train$stat_day_cnt <- NULL
# 构建均衡训练集
train_sample_true <- which(label == 1)
train_sample_false <- which(label == 0)
balanced_sample_size <- ceiling(length(train_sample_true) * 1.3)
true_index <- train_sample_true
false_index <- train_sample_false[sample(1:length(train_sample_false), balanced_sample_size)]
balanced_index <- c(true_index, false_index)
dtrain_balanced <- xgb.DMatrix(data = as.matrix(1.0*online_train[balanced_index, ]),
label=label[balanced_index])
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=10, eta=0.01, subsample=0.9)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=200, nfold=5)
# 训练模型（均衡样本）
train.xgboost.balanced <- xgb.train(data=dtrain_balanced, params=params, nrounds=1000)
# # 训练误差分析
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_train), label=label)
model <- train.xgboost.balanced
pred <- predict(model, dtrain)
tmp <- data.frame(label, pred)
tmp <- tmp %>% arrange(desc(pred))
precision <- sum(tmp$label[1:12000]) / 12000
recall <- sum(tmp$label[1:12000]) / sum(tmp$label)
f11 <- 6*recall*precision / (5*recall + precision)
# 提交预测
user_id <- online_prediction_x$user_id
online_prediction_x$user_id <- NULL
online_prediction_x$stat_day_cnt <- NULL
dtrain_online <- xgb.DMatrix(data = as.matrix(1.0*online_prediction_x))
pred <- predict(model, dtrain_online)
# 根据概率排序
result <- data.frame(user_id, pred)
result <- result %>% arrange(desc(pred))
result <- result[1:12000, ]
# 匹配SKU
load('E:/JData2017/action_all.RData')
product <- fread('E:/JData2017/JData_Product.csv')
sku_prediction <- action_all %>% filter(user_id %in% result$user_id & sku_id %in% product$sku_id)
rm(list = c('action_all')); gc()
sku_prediction <- sku_prediction %>% arrange(user_id, desc(time)) %>% group_by(user_id) %>% mutate(id=row_number()) %>% filter(id == 1)
result <- left_join(result, sku_prediction, by='user_id')
idx <- which(is.na(result$sku_id))
result$sku_id[idx] <- 162344
head(sku_prediction)
sku_prediction <- sku_prediction %>% arrange(user_id, desc(time)) %>% group_by(user_id) %>% mutate(id=row_number()) %>% filter(id == 1)
sku_prediction <- sku_prediction %>% dplyr::arrange(user_id, desc(time)) %>% group_by(user_id) %>% mutate(id=row_number()) %>% filter(id == 1)
sku_prediction <- sku_prediction %>% dplyr::arrange(user_id, desc(time)) %>% group_by(user_id) %>% dplyr::mutate(id=row_number()) %>% filter(id == 1)
head(sku_prediction)
result <- left_join(result, sku_prediction, by='user_id')
idx <- which(is.na(result$sku_id))
result$sku_id[idx] <- 162344
head(result)
result <- data.frame(user_id, pred)
result <- result %>% arrange(desc(pred))
result <- result[1:12000, ]
sku_prediction <- action_all %>% filter(user_id %in% result$user_id & sku_id %in% product$sku_id)
load('E:/JData2017/action_all.RData')
product <- fread('E:/JData2017/JData_Product.csv')
sku_prediction <- action_all %>% filter(user_id %in% result$user_id & sku_id %in% product$sku_id)
rm(list = c('action_all')); gc()
sku_prediction <- sku_prediction %>% dplyr::arrange(user_id, desc(time)) %>% group_by(user_id) %>% dplyr::mutate(id=row_number()) %>% filter(id == 1)
result <- left_join(result, sku_prediction, by='user_id')
head(result)
is.na(result$sku_id)
idx <- which(is.na(result$sku_id))
result$sku_id[idx] <- 162344
output <- result %>% select(user_id, sku_id)
getwd()
write.csv(output, file='output.csv', row.names=FALSE, quote=FALSE)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
train.xgboost.balanced <- xgb.train(data=dtrain_balanced, params=params, nrounds=500)
# # 训练误差分析
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_train), label=label)
model <- train.xgboost.balanced
pred <- predict(model, dtrain)
tmp <- data.frame(label, pred)
tmp <- tmp %>% arrange(desc(pred))
precision <- sum(tmp$label[1:12000]) / 12000
recall <- sum(tmp$label[1:12000]) / sum(tmp$label)
f11 <- 6*recall*precision / (5*recall + precision)
params <- list(objective="binary:logistic", nthread=5, max_depth=6, eta=0.01, subsample=0.9)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
params <- list(objective="binary:logistic", nthread=5, max_depth=5, eta=0.01, subsample=0.5)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=6, eta=0.01, subsample=0.5)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=6, eta=0.02, subsample=0.5)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
length(train_sample_true)
# 构建均衡训练集
train_sample_true <- which(label == 1)
train_sample_false <- which(label == 0)
balanced_sample_size <- ceiling(length(train_sample_true) * 1.5)
true_index <- train_sample_true
false_index <- train_sample_false[sample(1:length(train_sample_false), balanced_sample_size)]
balanced_index <- c(true_index, false_index)
dtrain_balanced <- xgb.DMatrix(data = as.matrix(1.0*online_train[balanced_index, ]),
label=label[balanced_index])
params <- list(objective="binary:logistic", nthread=5, max_depth=6, eta=0.02, subsample=0.5)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
xgb.importance(model)
xgb.importance(model=model)
# importance
imp <- xgb.importance(model=model)
feature_rank <- as.numeric(imp$Feature) + 1
print(colnames(online_prediction_x)[feature_rank])
# 构建均衡训练集
train_sample_true <- which(label == 1)
train_sample_false <- which(label == 0)
balanced_sample_size <- ceiling(length(train_sample_true) * 2)
true_index <- train_sample_true
false_index <- train_sample_false[sample(1:length(train_sample_false), balanced_sample_size)]
balanced_index <- c(true_index, false_index)
dtrain_balanced <- xgb.DMatrix(data = as.matrix(1.0*online_train[balanced_index, ]),
label=label[balanced_index])
params <- list(objective="binary:logistic", nthread=5, max_depth=6, eta=0.02, subsample=0.5)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
train.xgboost.balanced <- xgb.train(data=dtrain_balanced, params=params, nrounds=500)
# 训练误差分析
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_train), label=label)
model <- train.xgboost.balanced
pred <- predict(model, dtrain)
tmp <- data.frame(label, pred)
tmp <- tmp %>% arrange(desc(pred))
precision <- sum(tmp$label[1:12000]) / 12000
recall <- sum(tmp$label[1:12000]) / sum(tmp$label)
f11 <- 6*recall*precision / (5*recall + precision)
# 提交预测
user_id <- online_prediction_x$user_id
online_prediction_x$user_id <- NULL
online_prediction_x$stat_day_cnt <- NULL
dtrain_online <- xgb.DMatrix(data = as.matrix(1.0*online_prediction_x))
pred <- predict(model, dtrain_online)
# 根据概率排序
result <- data.frame(user_id, pred)
result <- result %>% arrange(desc(pred))
# 取前12000个作为提交结果
result <- result[1:12000, ]
# 匹配SKU
load('E:/JData2017/action_all.RData')
product <- fread('E:/JData2017/JData_Product.csv')
sku_prediction <- action_all %>% filter(user_id %in% result$user_id & sku_id %in% product$sku_id)
rm(list = c('action_all')); gc()
sku_prediction <- sku_prediction %>% dplyr::arrange(user_id, desc(time)) %>% group_by(user_id) %>% dplyr::mutate(id=row_number()) %>% filter(id == 1)
result <- left_join(result, sku_prediction, by='user_id')
idx <- which(is.na(result$sku_id))
result$sku_id[idx] <- 162344
output <- result %>% select(user_id, sku_id)
write.csv(output, file='output.csv', row.names=FALSE, quote=FALSE)
rm(list = ls())
gc()
source('E:/git-src/JData2017/rcode/online_pipeline.R', encoding = 'UTF-8', echo=TRUE)
rm(list = ls())
gc()
source('E:/git-src/JData2017/rcode/online_pipeline.R', encoding = 'UTF-8', echo=TRUE)
imp <- xgb.importance(model=train.xgboost.balanced)
feature_rank <- as.numeric(imp$Feature) + 1
feature_rank
length(feature_rank)
imp
# 特征选择
num_of_features <- 20
imp <- xgb.importance(model=train.xgboost.balanced)
feature_rank <- as.numeric(imp$Feature) + 1
feature_select_index <- feature_rank[1:num_of_features]
feature_select_index
# re-train
dtrain_balanced_fs <- xgb.DMatrix(data = as.matrix(1.0*online_train[balanced_index, feature_select_index]),
label = label[balanced_index])
# re-train
dtrain_balanced_fs <- xgb.DMatrix(data = as.matrix(1.0*online_train[balanced_index, ..feature_select_index]),
label = label[balanced_index])
params <- list(objective="binary:logistic", nthread=5, max_depth=6, eta=0.02, subsample=0.8)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced_fs, params=params, nrounds=1000, nfold=3)
params <- list(objective="binary:logistic", nthread=5, max_depth=3, eta=0.02, subsample=0.8)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced_fs, params=params, nrounds=1000, nfold=3)
params <- list(objective="binary:logistic", nthread=5, max_depth=3, eta=0.02, subsample=0.5)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced_fs, params=params, nrounds=1000, nfold=3)
params <- list(objective="binary:logistic", nthread=5, max_depth=3, eta=0.02, subsample=1)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced_fs, params=params, nrounds=1000, nfold=3)
params <- list(objective="binary:logistic", nthread=5, max_depth=3, eta=0.01, subsample=1)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced_fs, params=params, nrounds=1000, nfold=3)
params <- list(objective="binary:logistic", nthread=5, max_depth=3, eta=0.01, subsample=0.5)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced_fs, params=params, nrounds=1000, nfold=3)
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_train[, ..feature_select_index]), label=label)
pred <- predict(model, dtrain)
tmp <- data.frame(label, pred)
tmp <- tmp %>% arrange(desc(pred))
precision <- sum(tmp$label[1:12000]) / 12000
recall <- sum(tmp$label[1:12000]) / sum(tmp$label)
f11 <- 6*recall*precision / (5*recall + precision)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=6, eta=0.02, subsample=0.8)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=10, eta=0.02, subsample=0.8)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=1000, nfold=3)
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=10, eta=0.02, subsample=0.8)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=200, nfold=5)
# 设置参数
params <- list(objective="binary:logistic", nthread=5, max_depth=8, eta=0.02, subsample=0.8)
# 交叉验证
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=200, nfold=5)
train.xgboost.balanced <- xgb.train(data=dtrain_balanced, params=params, nrounds=200)
# 特征选择
num_of_features <- 30
imp <- xgb.importance(model=train.xgboost.balanced)
feature_rank <- as.numeric(imp$Feature) + 1
feature_select_index <- feature_rank[1:num_of_features]
# re-train
dtrain_balanced_fs <- xgb.DMatrix(data = as.matrix(1.0*online_train[balanced_index, ..feature_select_index]),
label = label[balanced_index])
params <- list(objective="binary:logistic", nthread=5, max_depth=8, eta=0.02, subsample=0.8)
train.xgboost.cv <- xgb.cv(data = dtrain_balanced_fs, params=params, nrounds=200, nfold=5)
train.xgboost.balanced.fs <- xgb.train(data=dtrain_balanced_fs, params=params, nrounds=300)
model <- train.xgboost.balanced.fs
# 训练误差分析
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_train), label=label)
dtrain <- xgb.DMatrix(data = as.matrix(1.0*online_train[, ..feature_select_index]), label=label)
pred <- predict(model, dtrain)
tmp <- data.frame(label, pred)
tmp <- tmp %>% arrange(desc(pred))
precision <- sum(tmp$label[1:12000]) / 12000
recall <- sum(tmp$label[1:12000]) / sum(tmp$label)
f11 <- 6*recall*precision / (5*recall + precision)
# 提交预测
user_id <- online_prediction_x$user_id
online_prediction_x$user_id <- NULL
online_prediction_x$stat_day_cnt <- NULL
dtrain_online <- xgb.DMatrix(data = as.matrix(1.0*online_prediction_x[, ..feature_select_index]))
pred <- predict(model, dtrain_online)
# 根据概率排序
result <- data.frame(user_id, pred)
result <- result %>% arrange(desc(pred))
# 取前12000个作为提交结果
result <- result[1:12000, ]
# 匹配SKU
load('E:/JData2017/action_all.RData')
product <- fread('E:/JData2017/JData_Product.csv')
sku_prediction <- action_all %>% filter(user_id %in% result$user_id & sku_id %in% product$sku_id)
rm(list = c('action_all')); gc()
sku_prediction <- sku_prediction %>% dplyr::arrange(user_id, desc(time)) %>% group_by(user_id) %>% dplyr::mutate(id=row_number()) %>% filter(id == 1)
result <- left_join(result, sku_prediction, by='user_id')
idx <- which(is.na(result$sku_id))
result$sku_id[idx] <- 162344
output <- result %>% select(user_id, sku_id)
write.csv(output, file='output.csv', row.names=FALSE, quote=FALSE)
online_prediction_x <- fread('../data/online_prediction_20170510113551.txt')
# 提交预测
user_id <- online_prediction_x$user_id
online_prediction_x$user_id <- NULL
online_prediction_x$stat_day_cnt <- NULL
dtrain_online <- xgb.DMatrix(data = as.matrix(1.0*online_prediction_x[, ..feature_select_index]))
pred <- predict(model, dtrain_online)
# 根据概率排序
result <- data.frame(user_id, pred)
result <- result %>% arrange(desc(pred))
# 取前12000个作为提交结果
result <- result[1:12000, ]
# 匹配SKU
load('E:/JData2017/action_all.RData')
product <- fread('E:/JData2017/JData_Product.csv')
sku_prediction <- action_all %>% filter(user_id %in% result$user_id & sku_id %in% product$sku_id)
rm(list = c('action_all')); gc()
sku_prediction <- sku_prediction %>% dplyr::arrange(user_id, desc(time)) %>% group_by(user_id) %>% dplyr::mutate(id=row_number()) %>% filter(id == 1)
result <- left_join(result, sku_prediction, by='user_id')
idx <- which(is.na(result$sku_id))
result$sku_id[idx] <- 162344
output <- result %>% select(user_id, sku_id)
write.csv(output, file='output.csv', row.names=FALSE, quote=FALSE)
?xgb.cv
result <- fread('D:/result.csv')
head(result)
colnames(result) <- c("user_id", "pred")
# 匹配SKU
load('E:/JData2017/action_all.RData')
product <- fread('E:/JData2017/JData_Product.csv')
sku_prediction <- action_all %>% filter(user_id %in% result$user_id & sku_id %in% product$sku_id)
rm(list = c('action_all')); gc()
sku_prediction <- sku_prediction %>% dplyr::arrange(user_id, desc(time)) %>% group_by(user_id) %>% dplyr::mutate(id=row_number()) %>% filter(id == 1)
result <- left_join(result, sku_prediction, by='user_id')
idx <- which(is.na(result$sku_id))
result$sku_id[idx] <- 162344
output <- result %>% select(user_id, sku_id)
write.csv(output, file='output.csv', row.names=FALSE, quote=FALSE)
# 评价函数
recall <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
labels_pred <- preds > 0.5
recall <- sum(labels_pred * labels)/sum(labels)
print(recall)
return(list(metric = "recall", value = recall))
}
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=200, nfold=5, feval=recall)
# 评价函数
recall <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
labels_pred <- preds > 0.5
recall <- sum(labels_pred * labels)/sum(labels)
return(list(metric = "recall", value = recall))
}
train.xgboost.cv <- xgb.cv(data = dtrain_balanced, params=params, nrounds=200, nfold=5, feval=recall)
